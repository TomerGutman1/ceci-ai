import OpenAI from 'openai'
import { Stream } from 'openai/streaming'
import { getAssistantConfig, getEvaluatorConfig } from '../llms/configs'
import { LLMReqParams } from '../types/prompts'
import { ResponseFunctionToolCall } from 'openai/resources/responses/responses'
import { ToolName } from '../llms/tools'
import { getDecisionSearchService } from '../services/decisionSearchService';

const openai = new OpenAI()

export async function getAssistantResponse(
  llmReqParams: LLMReqParams,
): Promise<Stream<OpenAI.Responses.ResponseStreamEvent>> {
  const promptConfig = getAssistantConfig(llmReqParams)
  console.log('[OpenAI] Assistant request with tools:', promptConfig.tools?.map(t => (t as any).function?.name || 'unknown'));
  console.log('[OpenAI] User message:', llmReqParams.newInput);
  const result = await openai.responses.create(promptConfig)

  return result
}

export async function getEvaluatorResponse(
  llmReqParams: LLMReqParams,
): Promise<OpenAI.Responses.Response> {
  const promptConfig = getEvaluatorConfig(llmReqParams)
  const result = await openai.responses.create(promptConfig)

  return result
}

export async function callFunction(
  toolCall: ResponseFunctionToolCall,
): Promise<[Error] | [undefined, string]> {
  try {
    const toolName = toolCall.name as ToolName;
    const toolArgs = JSON.parse(toolCall.arguments);
    
    console.log('\n========== TOOL CALL ==========');
    console.log('[callFunction] Tool name:', toolName);
    console.log('[callFunction] Tool args:', toolArgs);
    console.log('===============================\n');
    
    // Handle search_decisions tool
    if (toolName === 'search_decisions') {
      console.log('[OpenAI] Calling search_decisions with query:', toolArgs.search_query);
      
      try {
        const searchService = getDecisionSearchService();
        
        // Parse the query to understand user intent
        let requestedLimit = 10; // default
        const query = toolArgs.search_query;
        const queryLower = query.toLowerCase();
        
        // First check if the query uses singular form (×”×—×œ×˜×”) vs plural (×”×—×œ×˜×•×ª)
        const isSingularRequest = query.includes('×”×—×œ×˜×”') && !query.includes('×”×—×œ×˜×•×ª');
        
        // Check if there's a number or quantity word in the query
        const hasExplicitNumber = /\d+/.test(query) || 
          /(×©×ª×™×™×|×©×œ×•×©|××¨×‘×¢|×—××©|×©×©|×©×‘×¢|×©××•× ×”|×ª×©×¢|×¢×©×¨|×›××”|×”×¨×‘×”|×¢×•×“)/i.test(query);
        
        // If singular form without explicit number, assume 1
        if (isSingularRequest && !hasExplicitNumber) {
          requestedLimit = 1;
          console.log('[OpenAI] Detected singular request without number - limiting to 1');
        } else {
          // Enhanced number detection patterns
          const numberPatterns = [
            // Hebrew patterns
            /(×”×—×œ×˜×”\s+××—×ª)/i,  // "×”×—×œ×˜×” ××—×ª"
            /(××—×ª)\s+(×”×—×œ×˜×”|×‘×œ×‘×“|××”)/i, // "××—×ª ×”×—×œ×˜×”" or "××—×ª ×‘×œ×‘×“"
            /(×¨×§\s+××—×ª)/i,  // "×¨×§ ××—×ª"
            /(×”×—×œ×˜×”)\s+(×™×—×™×“×”|×‘×•×“×“×ª)/i, // "×”×—×œ×˜×” ×™×—×™×“×”"
            // Number patterns
            /(\d+)\s*(×”×—×œ×˜×”|×”×—×œ×˜×•×ª)/i,
            /(×”×—×œ×˜×”|×”×—×œ×˜×•×ª)\s*(\d+)/i,
            // English patterns
            /(one|single)\s+(decision)/i,
            /(decision)\s+(one|only)/i,
            /(just|only)\s+(one)/i,
            /(\d+)\s*(decision|decisions)/i
          ];
        
          // Check all patterns
          for (const pattern of numberPatterns) {
            const match = queryLower.match(pattern);
            if (match) {
              // Check if it's a "one" pattern
              if (match[0].includes('××—×ª') || match[0].includes('×™×—×™×“') || 
                  match[0].includes('one') || match[0].includes('single') ||
                  match[0].includes('×‘×•×“×“')) {
                requestedLimit = 1;
                console.log('[OpenAI] Detected request for ONE decision');
                break;
              }
              // Check for numeric value
              const numMatch = match[0].match(/\d+/);
              if (numMatch) {
                requestedLimit = parseInt(numMatch[0]);
                console.log(`[OpenAI] Detected request for ${requestedLimit} decisions`);
                break;
              }
            }
          }
        }
        
        console.log(`[OpenAI] Final requested limit: ${requestedLimit}`);
        
        const decisions = await searchService.searchDecisions(toolArgs.search_query, Math.min(requestedLimit, 50));
        const formattedResponse = searchService.formatDecisionsResponse(decisions);
        
        // Get total count for better context
        const allDecisions = await searchService.searchDecisions(toolArgs.search_query, 1000);
        const totalFound = allDecisions.length;
        
        // Add context about what was found
        let contextResponse: string;
        if (decisions.length > 0) {
          contextResponse = `## ğŸ” ×ª×•×¦××•×ª ×—×™×¤×•×©: "${toolArgs.search_query}"\n\n`;
          contextResponse += `× ××¦××• **${totalFound} ×”×—×œ×˜×•×ª** ×¨×œ×•×•× ×˜×™×•×ª ××ª×•×š ${searchService.getStatus().decisionCount} ×”×—×œ×˜×•×ª ×‘×××’×¨.\n`;
          
          if (requestedLimit === 1) {
            contextResponse += `×”× ×” ×”×”×—×œ×˜×” ×”××—×¨×•× ×” ×‘× ×•×©×:\n\n`;
          } else {
            contextResponse += `××•×¦×’×•×ª **${decisions.length} ×”×”×—×œ×˜×•×ª ×”××—×¨×•× ×•×ª**:\n\n`;
          }
          
          contextResponse += `---\n\n${formattedResponse}\n\n---\n\n`;
          
          // Add helpful tips
          if (totalFound > decisions.length) {
            contextResponse += `ğŸ’¡ **×˜×™×¤:** × ××¦××• ${totalFound - decisions.length} ×”×—×œ×˜×•×ª × ×•×¡×¤×•×ª. `;
            contextResponse += `×× ×ª×¨×¦×” ×œ×¨××•×ª ×¢×•×“, ×¤×©×•×˜ ×‘×§×© "×¢×•×“ ×”×—×œ×˜×•×ª" ××• ×¦×™×™×Ÿ ××¡×¤×¨ ×¡×¤×¦×™×¤×™.\n\n`;
          }
          
          contextResponse += `ğŸ” **×—×™×¤×•×©×™× × ×•×¡×¤×™× ×©×™×›×•×œ×™× ×œ×¢× ×™×™×Ÿ:**\n`;
          contextResponse += `- ×”×—×œ×˜×•×ª ×œ×¤×™ ××©×¨×“ ×¡×¤×¦×™×¤×™ (×œ××©×œ: "×”×—×œ×˜×•×ª ××©×¨×“ ×”×—×™× ×•×š")\n`;
          contextResponse += `- ×”×—×œ×˜×•×ª ××ª×§×•×¤×” ××¡×•×™××ª (×œ××©×œ: "×”×—×œ×˜×•×ª ×-2024")\n`;
          contextResponse += `- ×”×—×œ×˜×•×ª ×‘× ×•×©× ××©× ×” (×œ××©×œ: "${toolArgs.search_query} ×ª×§×¦×™×‘")\n\n`;
          
          if (decisions.length <= 3) {
            contextResponse += `ğŸ“Š ×× ×ª×¨×¦×”, ××•×›×œ ×œ×”×¢×¨×™×š ××ª ××™×›×•×ª ×”×‘×™×¦×•×¢ ×©×œ ××—×ª ××”×”×—×œ×˜×•×ª ×”×œ×œ×•.`;
          }
        } else {
          contextResponse = `## âŒ ×œ× × ××¦××• ×ª×•×¦××•×ª\n\n`;
          contextResponse += `×œ× ××¦××ª×™ ×”×—×œ×˜×•×ª ×××©×œ×” ×”×ª×•×××•×ª ×œ×—×™×¤×•×© "${toolArgs.search_query}".\n\n`;
          contextResponse += `### ğŸ’¡ ×”×¦×¢×•×ª ×œ×—×™×¤×•×© ××©×•×¤×¨:\n\n`;
          contextResponse += `1. **× ×¡×” ××™×œ×•×ª ××¤×ª×— ××—×¨×•×ª** - ×œ××©×œ, ×× ×—×™×¤×©×ª "×‘×ª×™ ×—×•×œ×™×", × ×¡×” "×‘×¨×™××•×ª" ××• "××¢×¨×›×ª ×”×‘×¨×™××•×ª"\n`;
          contextResponse += `2. **×¦×™×™×Ÿ ××©×¨×“ ×××©×œ×ª×™** - "×”×—×œ×˜×•×ª ××©×¨×“ ×”×‘×¨×™××•×ª"\n`;
          contextResponse += `3. **×”×•×¡×£ ×˜×•×•×— ×–××Ÿ** - "×”×—×œ×˜×•×ª ×-2023" ××• "×”×—×œ×˜×•×ª ××—×¨×•× ×•×ª"\n`;
          contextResponse += `4. **×”×©×ª××© ×‘× ×•×©× ×¨×—×‘ ×™×•×ª×¨** - "×ª×©×ª×™×•×ª" ×‘××§×•× "×›×‘×™×©×™×"\n\n`;
          contextResponse += `×“×•×’×××•×ª ×œ×—×™×¤×•×©×™× ××•×¦×œ×—×™×: ×—×™× ×•×š, ×‘×¨×™××•×ª, ×ª×§×¦×™×‘, ×‘×™×˜×—×•×Ÿ, ×“×™×•×¨, ×ª×—×‘×•×¨×”`;
        }
        
        return [undefined, contextResponse];
      } catch (error) {
        console.error('[OpenAI] Error in search_decisions:', error);
        return [undefined, '××¦×˜×¢×¨, × ×ª×§×œ×ª×™ ×‘×‘×¢×™×” ×‘×—×™×¤×•×© ×”×—×œ×˜×•×ª. ×× × × ×¡×” ×©×•×‘.'];
      }
    }

    // Handle evaluation tools (existing code)
    if (toolName === 'evaluate_existing_decision') {
      // Search for evaluation via decision & gov number
      // If exists - return existing evaluation
      // Else -
      // Evaluate decision, return it
      // return
    }
  
    // Else - evaluate draft and return it
    const evaluationRes = await getEvaluatorResponse({
      newInput: [{ role: 'user', content: toolArgs.decision_text }],
      promptId: 'EVALUATION_PROMPT',
    })
  
    return [undefined, evaluationRes.output_text]
  } catch (error) {
    return [error as Error]
  }
}
